{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Kalindu's Homelab","text":"<p>https://kdecosta.com/homelab/</p> <p> </p> <p>This repository contains the a collection of documentation and the architecture my homelab which includes network architecture as well as IoC and scripts used for automation of hosted services.</p>"},{"location":"#lab-goals","title":"Lab goals","text":""},{"location":"#managed-network-omada","title":"Managed Network (Omada)","text":"<ol> <li>VLANs for device groups</li> <li>Custom SSIDs</li> <li>Network throughput monitoring</li> <li>Support POE devices</li> <li>Custom recursive DNS server / Local DNS</li> </ol>"},{"location":"#hosted-services","title":"Hosted Services","text":"<ol> <li>Virtualized containers</li> <li>Kubernetes for service management</li> <li>Monitoring with Prometheus and Grafana</li> <li>GitLabs server for GitOps / deploys</li> <li>VPN for remote management</li> <li>Load-balancer (envoy / ingress-nginx)</li> </ol>"},{"location":"#backup-archival-storage","title":"Backup / Archival Storage","text":"<ol> <li>TrueNAS for archival and backup storage</li> </ol>"},{"location":"#ioc-and-gitops","title":"IoC and GitOps","text":"<ol> <li>Ansible for container automation</li> <li>Terraform for infrastructure management</li> <li>ChatOps (slack??)</li> </ol>"},{"location":"#security-resiliency","title":"Security / Resiliency","text":"<ol> <li>Certificate management</li> <li>Cloudflare tunnel for exposed services</li> </ol>"},{"location":"#demos-and-screenshots","title":"Demos and Screenshots","text":""},{"location":"#license","title":"License","text":"<p>Distributed under the MIT License, go nuts.</p>"},{"location":"lab/","title":"The Lab","text":"<p>Welcome to the lab timeline. I am going to use this space as place to record a timeline of how the lab evolves over time. Every update will build on top of the other, there will be some repeated information just for context, but most updates will only include new and updated changes to the lab.</p>","tags":["hardware","rack","lab"]},{"location":"lab/#timeline","title":"Timeline","text":"","tags":["hardware","rack","lab"]},{"location":"lab/#20230324","title":"2023/03/24","text":"<p>The journey begins. Complete overview of all hardware in the lab.</p> <p> 2023</p>","tags":["hardware","rack","lab"]},{"location":"lab/updates/update_20230324/","title":"The Journey Begins - 2023/03/24","text":"","tags":["hardware","rack","lab","omada"]},{"location":"lab/updates/update_20230324/#overview","title":"Overview","text":"<p>This is the first update of the lab. I am planning to post an update at least twice a year, but let's see how the lab will progress. I am going to try to go into as much detail as possible on the hardware choices, organization and types of services.</p> <p>Lets, begin...</p>","tags":["hardware","rack","lab","omada"]},{"location":"lab/updates/update_20230324/#hardware-breakdown","title":"Hardware breakdown","text":"<p>The lab is still in it's early stages. I am still figuring out the organizations and the choice of hardware to best achieve the goals for this project. Before getting into all the specifics, let's go over the hardware.</p> Legend A. Brush panel B. ER7206 (router) C. OC200 (cloud controller) D. TL-SG2210MP (POE switch) E. Patch Panel F. TL-SG2218 (16 Port switch) G. SBC array (BananaPI-M5 x2) H. USFF array (ThinkCenter M73 x3) I. 2 port KVM switch J. Hubitat C-7 K. CyberPower CPS1215RM (10 Port PDU x2) L. CyberPower EC850LCD UPS <p></p> <p>Top down I am organizing the rack in to 3 sections, network, servers, and power with some basic organization panels added in between. I have 15U of space for this organization and for now I am dedicating 6U of space for the network section, 5U for the server section and 4U for the power section. There is a lot or room for improvement here, but with the equipment I have this is the best way I can think of to organize the hardware for easy access and \"clean\" cable management.</p>","tags":["hardware","rack","lab","omada"]},{"location":"lab/updates/update_20230324/#network","title":"Network","text":"<p>I decided very early on to stick to a single ecosystem for my networking gear, primarily for the ease of use and integration and for the community support. There were a few options here, Ubiquity (r/homelabs favourite), <code>Omada</code>, Cisco, Aruba ... My homelab journey started in late 2021, well into the global supply chain issues and getting anything Ubiquity was nearly impossible. Cisco and Aruba had a great community behind it but was too expensive for a home setup and that left TPLink <code>Omada</code>, somewhat underrated and so far has worked really well for this project.</p> <p>To start this section, there is a brush panel [A]. It's mostly there as a filler and for some organization. In the future, I am planning to get rid of this panel to make some room for a another switch or a 1U server. Next we get to the interesting bits. First we start with the ER7206 (gigabit router) [B] and the OC200 (cloud controller) [C] fitted into a custom 3D printed rack mount case that I got through etsy. The OC200 is really handy and enables automatic hardware provisioning and provides very easy to use <code>Omada</code> dashboard along with remote management for all your adopted <code>Omada</code> devices. It's very beginner friendly. My only experience with networking before starting this journey was port-forwarding through my ISP provided modem/router.</p> <p>Next, I have a TL-SG2210MP, an 8 port POE switch [D] and a patch panel [E]. I found these second hand for very cheap and it has worked without any issue for the past 2ish years now. The OC200 and all my home APs are POE powered. I will eventually have to upgrade this to something like a 16 or a 24 port POE switch when I add a few more POE cameras into my home and eventually convert all The SBCs in the rack to power over POE.</p> <p>To finish off this section, I have a TL-SG2218, a 16 port switch [F] and another brush panel for some organization. I am very quickly running out of ports for this switch and I will probably upgrade this switch in the next few months.</p>","tags":["hardware","rack","lab","omada"]},{"location":"lab/updates/update_20230324/#server","title":"Server","text":"<p>This section is really the meat of the lab. It starts with my SBC array [G], so far I only have 2 BananaPI M5s. I want to add a couple more SBCs in here and try to power it all with POE (raspberry PIs please come back ).</p> <p>Next, I have the USFF array [H]. This is my virtualization cluster running Proxmox VE. They are all used vanilla ThinkCenter M73s (around $50 - $80 on marketplace), eventually I want to upgrade these with some 4tb SSDs and max out the RAM (16gb DDR3). I decided to go with some Tiny PCs here because of 1. costs, they are very cheap and 2. rack space. This rack is a very short depth rack and standard depth servers are impossible to fit in it. Even some short depth servers are a tough fit.</p> <p>To finish off this section, I have a 2 port KVM switch [I] and a Hubitat C-7 [J]. The KVM switch is really underpowered and not super useful. I want to switch this out for a good, 8 port KVM switch or a DIY PiKVM solution.</p>","tags":["hardware","rack","lab","omada"]},{"location":"lab/updates/update_20230324/#power-and-storage","title":"Power (and storage)","text":"<p>The final section, power and sort of storage. This section is not organized well. The first two are CyberPower CPS1215RMs [K], some basic 10 outlet PDUs connected to the CyberPower EC850LCD UPS [L]. During a power outage, this provides about 10-15 minutes of continuous power, which is plenty to safely power off the servers. Plus, the UPS supports data over USB to run some automation to safely shutoff critical devices when running off the battery.</p>","tags":["hardware","rack","lab","omada"]},{"location":"lab/updates/update_20230324/#energy-usage","title":"Energy usage","text":"<p>On average the whole rack draws around 83W of power, this roughly translates to around $5-$6 / month, here in Ontario, Canada. This is really not too bad considering the capabilities of the lab. I could probably improve this further by picking some more efficient USFF computers, but I am quite happy with the current energy usage.</p>","tags":["hardware","rack","lab","omada"]},{"location":"lab/updates/update_20230324/#daily-power-draw","title":"Daily power draw","text":"","tags":["hardware","rack","lab","omada"]},{"location":"lab/updates/update_20230324/#daily-energy-cost","title":"Daily energy cost","text":"","tags":["hardware","rack","lab","omada"]},{"location":"lab/updates/update_20230324/#network-and-services","title":"Network and Services","text":"<p>Ok so, the hardware is nice, but what do I really run with all this? Well first, let's take a look at how the network devices are connected. One of the goals I have for this project is to learn more about VLANs and L3 network management. I have multiple VLANs setup to segregate and monitor network devices like personal devices, IoT devices, administrative devices, etc. This also allows me to manage which devices can talk to each other with use of firewall at a VLAN level.</p>","tags":["hardware","rack","lab","omada"]},{"location":"lab/updates/update_20230324/#network-topology","title":"Network topology","text":"<p>There are 4 distinct VLANs in use within the lab. <code>IoT</code> VLAN for grouping all IoT devices, these include smart home devices, media devices, appliances, etc. <code>Work</code>, groups together all personal devices in the home like desktop computers, laptops, phones. This is also the primary VLAN for the the home WiFi. <code>Access</code>, is reserved for devices that require acccess to everything on the network, like DNS service, monitoring and log aggregation services. Finally, the <code>servers</code> VLAN groups together all devices that act as servers in the lab like the SBC array, USFF array and the NAS server.</p> <p>The <code>IoT</code> devices are isolated from most other devices. Most devices on the <code>IoT</code> group does not require any communication with any other VLANs. Similarly, None of the VLANs are allowed to communicate with devices in the top level <code>LAN</code> group which includes the network devices. One of the devices I regret not including in the <code>IoT</code> VLAN is the Hubitat, I included it in the <code>access</code> VLAN to avoid some connectivity issues however, I think this was a configuration error on my part. I could spend a weekend re-configuring the Hubitat into the <code>IoT</code> VLAN, but I plan completely remove this device in favour of Zigbee and ZWave integration directly into the Home Assistant deployment. I am currently only using the Hubitat as a middle man to communicate with Zigbee / ZWave devices and all my home automation is done through Home Assistant.</p>","tags":["hardware","rack","lab","omada"]},{"location":"lab/updates/update_20230324/#services","title":"Services","text":"<p>So what services have I deployed in the Lab? I have a PiHole container deployed in one of the SBCs running as my primary DNS server for all VLANs, this allows me to block popular ad-servers directly for all devices in my Home. I am also leveraging the local DNS functionality of the PiHole for resolving static IPs for other devices. For example, <code>homeassistant.local</code> resolves to the static IP of my home assistant container.</p> <p>Next, similar to the PiHole, I have Home Assistant deployed in to a dedicated SBC running as the primary home automation system for all smart devices. I am also using home assistant as the primary dashboard for device controls and energy monitoring system for the home.</p> <p> </p> Home Assistant dashboard <p>Finally, each of the servers in the USFF array runs Proxmox VE for virtualization. I have a container running a prometheus and a loki server for metrics and log collection. All systems in the rack run prometheus exporters and log exporters through docker for exporting metrics and logs. This container also runs a Grafana server for metrics visualization and alert management for the whole rack. I am still in the early stages of learning proxmox for virtualization and eventually as a long term goal for this year, I want to build a kubernetes cluster in Proxmox and run all my deployments as services in kubernetes. This will allow me to automate deployments and use terraform for IaC.</p>","tags":["hardware","rack","lab","omada"]},{"location":"lab/updates/update_20230324/#whats-next","title":"What's next?","text":"<ul> <li>In terms of the rack, I want to do some proper cable management. I haven't shown the back of the rack in this update but it's ugly </li> <li>For services I want to build a kubernetes cluster in proxmox and move all my deployments into kubernetes</li> <li>Research Ansible playbooks and automate container deployment in proxmox</li> <li>GitOps with github or a self hosted git server and CI/CD</li> <li>L7 load balancer with custom DNS using either envoy or ingress-nginx (or something new, rust based nginx???)</li> <li>Resiliency for critical services like the PiHole and the Home Assistant with active-active deployments</li> <li>Regular backups of all persistent data</li> <li>Integrate Home Assistant DB into MySQL or Postgress</li> <li>Bare metal kubernetes using the SBCs??? (idk what I will do with this, but could be a good learning opportunity)</li> <li>Single command provisioning of new servers</li> <li>TrueNas server (need money for drives and a new rack for to fit a proper server )</li> </ul>","tags":["hardware","rack","lab","omada"]},{"location":"network/bypass_bell_homehub/","title":"Bypass Bell HomeHub 4000","text":"<p>Just let me use my own hardware :'(</p> <p>Bell Canada provides an all in one proprietary hardware solution for home networking. This is quite limited for my overall goals for this project. Using my own networking hardware allows to easily switch ISPs and without having to lockin to a single ISP. Using my own hardware also allow for better security and resiliency with better community support. For the purposes of this guide, I have the <code>HomeHub 4000</code> and all instructions are for working with the <code>HomeHub 4000</code>.</p>"},{"location":"network/bypass_bell_homehub/#option-1-advanced-dmz","title":"Option 1: Advanced DMZ","text":"<p>Update 2023/02/02</p> <p>This does not work for me anymore. A firmware update to the HH4000 somehow blacklisted my router. Enabling <code>Advanced DMZ</code> for the router now results in an invalid public ip for the router, and breaks the internet connection to the HH4000 as well.</p>"},{"location":"network/bypass_bell_homehub/#turn-on-dmz","title":"Turn ON DMZ","text":"<ol> <li>Connect router to one of the LAN port (or the 10G port)</li> <li>Visit <code>192.168.2.1</code>, enter HH4000 password <code>(defaults to the serial number of the device)</code></li> <li>Go to <code>Advanced Tool and Settings</code></li> <li>Click on <code>DMZ</code></li> <li>Enable <code>Advanced DMZ</code></li> <li>From the list of devices, locate the <code>MAC</code> address of the router</li> <li>Click on the router and select <code>Activate Device</code></li> <li>Save!</li> </ol>"},{"location":"network/bypass_bell_homehub/#additional-settings","title":"Additional Settings","text":"<ol> <li>Go to <code>Advanced Tool and Settings</code></li> <li>Turn OFF <code>UPnP, DLNA, and SIP ALG</code></li> <li>Select <code>WIFI</code> and disable the onboard wifi, we will be using our own router and APs</li> </ol>"},{"location":"network/bypass_bell_homehub/#calibration-steps","title":"Calibration Steps","text":"<ol> <li>Turn OFF both your router and the HH400 (pull the power cords) for 5-10 mins</li> <li>Turn ON the router and let is completely boot up (this HAS to power on first)</li> <li>Turn ON the HH400</li> </ol> <p>The router should now receive a valid IP and internet. If not, try the above steps again.</p> <p>Note</p> <p>In the event of a power failure, you may have to repeat the above steps for the router to receive a valid public IP. I would first try with the <code>Calibration Steps</code> first to see if the router can acquire a valid public IP.</p>"},{"location":"network/bypass_bell_homehub/#option-2-pppoe-passthrough","title":"Option 2: PPPoE Passthrough","text":""},{"location":"network/bypass_bell_homehub/#turn-off-unnecessary-settings","title":"Turn OFF unnecessary settings","text":"<ol> <li>Connect router to one of the LAN port (or the 10G port)</li> <li>Visit <code>192.168.2.1</code>, enter HH4000 password <code>(defaults to the serial number of the device)</code></li> <li>Go to <code>Advanced Tool and Settings</code></li> <li>Turn OFF <code>UPnP, DLNA, and SIP ALG</code></li> <li>Select <code>WIFI</code> and disable the onboard wifi, we will be using our own router and APs</li> </ol>"},{"location":"network/bypass_bell_homehub/#find-your-pppoe-credentials","title":"Find your PPPoE credentials","text":"<ol> <li>Login to myBell</li> <li>Go to <code>My Services &gt; Internet</code> and record the userID (it should start with <code>b1</code>)</li> <li>Under <code>Settings</code>, select <code>Change modem access password</code> and create a new access password</li> </ol>"},{"location":"network/bypass_bell_homehub/#configure-your-router","title":"Configure your router","text":"<p>I currently use a TPLink ER7206 as my router and I will be using this as an example of configuring PPPoE passthrough.</p> <ol> <li>Head over to <code>Settings &gt; Wired Networks &gt; Internet</code></li> <li>Select the appropriate <code>WAN</code> setting, I am using the regular RJ45 <code>WAN</code> port on the router to connect to HH400</li> <li>Set <code>Connection Type</code> to PPPoE</li> <li>Add the bell PPPoE credentials (the username/password that were acquired in the previous step)</li> <li>Expand <code>Advanced Settings</code></li> <li>Enable <code>Get IP Address from ISP</code></li> <li>Change the DNS Server to your preferred DNS server provider, I am going use google (8.8.8.8/8.4.4.8)</li> <li>Enable <code>Internet VLAN</code> and use 35 as the tagged value</li> <li>Restart the router!!!</li> </ol> <p></p>"}]}